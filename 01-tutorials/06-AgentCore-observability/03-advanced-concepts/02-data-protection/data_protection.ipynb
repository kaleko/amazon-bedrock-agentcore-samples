{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c80e0c1c-bd48-49b6-a830-aaa617e6a892",
   "metadata": {},
   "source": [
    "# Amazon Bedrock AgentCore Observability: Data Protection\n",
    "\n",
    "As organizations increasingly adopt agentic AI systems to automate complex workflows and decision-making processes, protecting sensitive data has become a critical concern. AI agents often handle personally identifiable information (PII), financial data, health records, and other confidential information that must be safeguarded throughout the agent's lifecycle, from input processing to output generation.\n",
    "\n",
    "This notebook demonstrates a comprehensive approach to protecting sensitive data in agentic AI applications by combining Amazon Bedrock Guardrails and Amazon CloudWatch Logs Data Protection policies. While we'll be hosting our agent on the AgentCore runtime using the Strands framework for this demonstration, these data protection principles and techniques can be applied to agents hosted on any runtime and any framework, making the concepts platform-agnostic and adaptable to your existing agent infrastructure.\n",
    "\n",
    "\n",
    "# What You'll Learn\n",
    "In this hands-on tutorial, we'll explore:\n",
    "\n",
    "- How to detect sensitive information in the Agent interactions and CloudWatch Logs and Traces \n",
    "- Amazon Bedrock Guardrails: How to configure sensitive information filters to prevent AI agents from processing or generating sensitive content\n",
    "- CloudWatch Logs Data Protection: How to automatically detect and mask sensitive data in application logs, ensuring PII and other confidential information don't leak through logging mechanisms\n",
    "- AgentCore Integration: How to implement these protective measures within agentic workflows, creating a defense-in-depth strategy for your AI applications\n",
    "\n",
    "# Why This Matters\n",
    "\n",
    "Without proper safeguards, agentic AI systems can:\n",
    "\n",
    "- Inadvertently expose sensitive customer data in responses or logs\n",
    "- Process or retain information that violates privacy regulations (GDPR, HIPAA, CCPA)\n",
    "- Generate outputs containing PII that shouldn't be shared\n",
    "- Create compliance and security vulnerabilities in your application infrastructure\n",
    "\n",
    "By implementing Bedrock Guardrails and CloudWatch Logs Data Protection together, you create multiple layers of protection that work in tandem to secure your agentic AI applications from input to output to logging.\n",
    "\n",
    "\n",
    "# View observability data for your Amazon Bedrock AgentCore agents\n",
    "\n",
    "After implementing observability in your agent, you can [view the collected logs, metrics and traces](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/observability-view.html) in both the CloudWatch console generative AI observability page and in CloudWatch Logs. To learn more about using generative AI observability in CloudWatch, including how to look at your agents' individual session and trace data, see [Amazon Bedrock AgentCore agents](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/AgentCore-Agents.html) in the Amazon CloudWatch user guide.\n",
    "\n",
    "`AgentCore agent log groups have the following format`:\n",
    "\n",
    "`1. Standard Logs`\n",
    "\n",
    "- Standard logs format: stdout/stderr output\n",
    "- Location: /aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/[runtime-logs] <UUID>\n",
    "- Contains: Runtime errors, application logs, debugging statements\n",
    "\n",
    "Example Usage:\n",
    "- print(\"Processing request...\") # Appears in standard logs\n",
    "- logging.info(\"Request processed successfully\") # Appears in standard logs\n",
    "\n",
    "\n",
    "`2. OTEL structured logs - Detailed operation information`\n",
    "\n",
    "- Location: /aws/bedrock-agentcore/runtimes/<agent_id>-<endpoint_name>/otel-rt-logs\n",
    "- Contains: Execution details, error tracking, performance data\n",
    "- Automatic collection: No additional code required - generated by ADOT instrumentation\n",
    "- Benefits: Can include correlation IDs linking logs to relevant traces\n",
    "\n",
    "`3. Traces and Spans`\n",
    "\n",
    "Traces provide visibility into request execution paths through your agent:\n",
    "\n",
    "- Location: /aws/spans/default\n",
    "- Access via: CloudWatch Transaction Search console\n",
    "- Requirements: CloudWatch Transaction Search must be enabled\n",
    "\n",
    "Traces automatically capture:\n",
    "- Agent invocation sequences\n",
    "- Integration with framework components (LangChain, etc.)\n",
    "- LLM calls and responses\n",
    "- Tool invocations and results\n",
    "- Error paths and exceptions\n",
    "\n",
    "\n",
    "<span style=\"color:red;\">For this lab, we will focus on protecting the Standard logs.</span>\n",
    "\n",
    "# Prerequisites\n",
    "\n",
    "- Enable transaction search on Amazon CloudWatch. First-time users must [enable CloudWatch Transaction Search](../../00-enable-transaction-search-template/enable_transaction_search.ipynb) to view Bedrock AgentCore spans and traces.\n",
    "- AWS account with Amazon Bedrock Model access to Claude Sonnet 3.7 with Model ID: us.anthropic.claude-3-7-sonnet-20250219-v1:0\n",
    "- AWS credentials configured using aws configure\n",
    "- Grant appropriate IAM permissions required to create or work with a data protection policy [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/data-protection-policy-permissions.html), Bedrock Guardrails and AgentCore\n",
    "\n",
    "\n",
    "# 1. Setup and configuration\n",
    "\n",
    "Install the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84413231-f8c3-42c3-bd28-4120670a3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b403b00c-df3f-44a9-ad60-11c653dfb9f1",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Create an Agent without data protection enabled\n",
    "\n",
    "Lets run an Agent first without any data protection enabled and examine the results. For this, we are using a sample dataset of a Contact Center Agent interaction with their Customer, which contains sensitive information. You can examine the contents [here](./data/customer_support_conversation_sample.txt). We updated the Agent prompt to summarize the conversation in the sample data provided.\n",
    "\n",
    "We also added sensitive information in the `print` statements as below:\n",
    "\n",
    "            \"agent.type\": \"customer_agent_reviewer\",\n",
    "            \"agent.email\": \"jrussell@domain.com\",\n",
    "            \"agent.phone\": \"301-555-0100\",\n",
    "            \"agent.id\": \"ABCDE12345\"\n",
    "\n",
    "We intentionally prompted the Agent to reveal sensitive information as below:\n",
    "            \n",
    "            user_input = \"\"\"summarize the agent conversation. Tell me exactly the phone number, name, address, and email?\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eacc84-b62b-4fdf-a7d0-5554734f697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile data_protection.py\n",
    "import os\n",
    "import logging\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure Strands logging\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "@tool\n",
    "def agent_call_summary(query: str) -> str:\n",
    "    \"\"\"Summarizing the contact center agent interaction.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Processing agent call summary for query: {query[:50]}...\")\n",
    "        \n",
    "        # Read the customer support conversation data\n",
    "        results = open('./data/customer_support_conversation_sample.txt', 'r').read()\n",
    "        \n",
    "        logger.info(f\"Agent conversation search completed successfully for query: {query[:50]}...\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Agent call summary failed: {str(e)}\")\n",
    "        return f\"Search error: {str(e)}\"\n",
    "\n",
    "def get_bedrock_model():\n",
    "    model_id = os.getenv(\"BEDROCK_MODEL_ID\", \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n",
    "    \n",
    "    try:\n",
    "        bedrock_model = BedrockModel(\n",
    "            model_id=model_id,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1028         \n",
    "        )\n",
    "        logger.info(f\"Successfully initialized Bedrock model: {model_id}\")\n",
    "        return bedrock_model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Bedrock model: {str(e)}\")\n",
    "        logger.error(\"Please ensure you have proper AWS credentials configured and access to the Bedrock model\")\n",
    "        raise\n",
    "\n",
    "# Initialize the model and agent\n",
    "bedrock_model = get_bedrock_model()\n",
    "\n",
    "\n",
    "# Create customer support agent\n",
    "support_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=\"\"\"You are an expert customer support conversation agent specializing in finding \n",
    "                     accurate and relevant information. Your role is to efficiently search, analyze, and synthesize\n",
    "                     information provided to answer user queries comprehensively. You should provide\n",
    "                     well-researched responses with current information, clear summaries, and cite reliable sources\n",
    "                     when presenting your findings.\"\"\",\n",
    "    tools=[agent_call_summary],\n",
    "    trace_attributes={        \n",
    "        \"tags\": [\"Strands\", \"Observability\", \"CustomerSupport\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def customer_support_agent(payload):\n",
    "    \"\"\"Invoke the customer support agent with a payload\"\"\"\n",
    "    try:\n",
    "        # Extract user input from payload\n",
    "        user_input = payload.get(\"prompt\", \"\")\n",
    "        \n",
    "        logger.info(f\"User input: {user_input[:100]}...\")\n",
    "\n",
    "        print(\"agent.type: customer_agent_reviewer\")\n",
    "        print(\"agent.email: jrussell@domain.com\")\n",
    "        print(\"agent.phone: 301-555-0100\")\n",
    "        print(\"agent.id: ABCDE12345\")\n",
    "        \n",
    "        # If no specific query provided, use default\n",
    "        if not user_input:\n",
    "            user_input = \"summarize the agent conversation. Tell me exactly the phone number, name, address, and email.\"\n",
    "        \n",
    "        # Execute the customer research task\n",
    "        response = support_agent(user_input)\n",
    "        \n",
    "        logger.info(\"Agent response generated successfully\")\n",
    "        return response.message['content'][0]['text']\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Agent execution failed: {str(e)}\")\n",
    "        return f\"Error processing request: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8800ca-cfb6-46c4-b0f1-a68f26bc170e",
   "metadata": {},
   "source": [
    "\n",
    "# Deploy the agent to AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607f68e-25d1-441e-8330-a53a2faf6f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "agent_name = \"customer_support_agent\"\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"data_protection.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region,\n",
    "    agent_name=agent_name,\n",
    "    memory_mode='NO_MEMORY'\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f626028d",
   "metadata": {},
   "source": [
    "# Launching agent to AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c03944",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ccd287",
   "metadata": {},
   "source": [
    "# Invoking AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a896876",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"summarize the agent conversation. Tell me exactly the phone number, name, address, and email.\"})\n",
    "invoke_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08c2f7fa-d984-4a7e-bb63-372a46a982b3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lets review the results starting with the Agent interaction here. Note: Your generated responses may be different, but the concept still applies!)\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/agent_response_without_data_protection.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "CloudWatch Trace:\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/trace_without_data_protection.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "CloudWatch Logs (Agent runtime logs):\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/logs_without_data_protection.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bff62fc-a1dc-41b9-ae4c-cecdda5ea322",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Enable Bedrock Guardrails\n",
    "\n",
    "Guardrails for Amazon Bedrock evaluates user inputs and FM responses based on use case specific policies, and provides an additional layer of safeguards regardless of the underlying FM. Guardrails can be applied across all large language models (LLMs) on Amazon Bedrock, including fine-tuned models. Customers can create multiple guardrails, each configured with a different combination of controls, and use these guardrails across different applications and use cases.\n",
    "\n",
    "You can use Amazon Bedrock Guardrails in multiple ways to help safeguard your generative AI applications. For example:\n",
    "\n",
    "- A chatbot application can use guardrails to help filter harmful user inputs and toxic model responses.\n",
    "- A banking application can use guardrails to help block user queries or model responses associated with seeking or providing investment advice.\n",
    "- A call center application to summarize conversation transcripts between users and agents can use guardrails to redact users’ personally identifiable information (PII) to protect user privacy.\n",
    "\n",
    "Guardrails for Amazon Bedrock have multiple components which include Content Filters, Denied Topics, Word and Phrase Filters, and Sensitive information (PII, PHI) Filters. For a full list check out the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails.html).\n",
    "\n",
    "For this exercise, we will focus only on safegurding Sensitive Information. \n",
    "\n",
    "Create a Bedrock Guardrail as below. To demonstrate guardrails, we anonymized the sensitive information, but you can chose to completely `BLOCK` the prompts/responses. To learn about all the sensitive information filters that are available, refer to the [documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-sensitive-filters.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40776a-f1ad-4a53-8715-593776ccf85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "bedrock_client = boto3.client('bedrock')\n",
    "\n",
    "create_response = bedrock_client.create_guardrail(\n",
    "    name='sensitive-information',\n",
    "    description='Prevents the model from revealing sensitive information including PII and PHI.',\n",
    "    sensitiveInformationPolicyConfig={\n",
    "        'piiEntitiesConfig': [\n",
    "            {\n",
    "                'type': 'EMAIL',\n",
    "                'action': 'ANONYMIZE'\n",
    "            },\n",
    "            {\n",
    "                'type': 'PHONE',\n",
    "                'action': 'ANONYMIZE'\n",
    "            },\n",
    "            {\n",
    "                'type': 'NAME',\n",
    "                'action': 'ANONYMIZE'\n",
    "            },\n",
    "            {\n",
    "                'type': 'US_SOCIAL_SECURITY_NUMBER',\n",
    "                'action': 'ANONYMIZE'\n",
    "            },\n",
    "            {\n",
    "                'type': 'US_BANK_ACCOUNT_NUMBER',\n",
    "                'action': 'ANONYMIZE'\n",
    "            },\n",
    "            {\n",
    "                'type': 'CREDIT_DEBIT_CARD_NUMBER',\n",
    "                'action': 'ANONYMIZE'\n",
    "            }\n",
    "        ],\n",
    "        'regexesConfig': [\n",
    "            {\n",
    "                'name': 'Account Number',\n",
    "                'description': 'Matches account numbers in the format XXXXXX1234',\n",
    "                'pattern': r'\\b\\d{6}\\d{4}\\b',\n",
    "                'action': 'ANONYMIZE'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging='Sorry, guardrails intervened and model cannot answer the question.',\n",
    "    blockedOutputsMessaging='Sorry, guardrails intervened and model cannot answer the question.',\n",
    ")\n",
    "\n",
    "print(create_response)\n",
    "guardrailId = create_response['guardrailId']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9f702-a5c0-4e50-9030-52d3e76b407d",
   "metadata": {},
   "source": [
    "\n",
    "Create a new version of the guardrail to use against the Agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f188b-896e-48f4-83ef-461ea2741d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_response = bedrock_client.create_guardrail_version(\n",
    "    guardrailIdentifier=guardrailId,\n",
    "    description='Version of Guardrail that has HIGH content filters across'\n",
    ")\n",
    "guardrail_version_number = version_response['version']\n",
    "\n",
    "print(guardrail_version_number)\n",
    "print(version_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7817c6d-528e-4f99-b5cc-7cbf15bcc2c3",
   "metadata": {},
   "source": [
    "\n",
    "Lets apply the newly created Guardrail to the Agent as below:\n",
    "\n",
    "            guardrail_id=os.getenv(\"BEDROCK_GUARDRAIL_ID\"),      # Your Bedrock guardrail ID\n",
    "            guardrail_version=os.getenv(\"BEDROCK_GUARDRAIL_VERSION\"),                   # Guardrail version\n",
    "            guardrail_trace=\"enabled\",               # Enable trace info for debugging \n",
    "\n",
    "To learn more about how to apply guardrails to Strands Agents, check out the [documentation](https://strandsagents.com/latest/documentation/docs/user-guide/safety-security/guardrails/).\n",
    "\n",
    "Note: For your convenience, in this lab, we used the same guardrail id and version number created from above. But you can replace with your specific guardrailId and version as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c51b3-b3f9-4377-aec0-8c609c9d2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile data_protection.py\n",
    "import os\n",
    "import logging\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configure Strands logging\n",
    "logging.getLogger(\"strands\").setLevel(logging.INFO)\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def agent_call_summary(query: str) -> str:\n",
    "    \"\"\"Summarizing the contact center agent interaction.\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Processing agent call summary for query: {query[:50]}...\")\n",
    "        \n",
    "        # Read the customer support conversation data\n",
    "        results = open('./data/customer_support_conversation_sample.txt', 'r').read()\n",
    "        \n",
    "        logger.info(f\"Agent conversation search completed successfully for query: {query[:50]}...\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Agent call summary failed: {str(e)}\")\n",
    "        return f\"Search error: {str(e)}\"\n",
    "\n",
    "def get_bedrock_model():\n",
    "    model_id = os.getenv(\"BEDROCK_MODEL_ID\", \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n",
    "    \n",
    "    logger.info(f\"BEDROCK_GUARDRAIL_ID: {os.getenv('BEDROCK_GUARDRAIL_ID')}\")\n",
    "    logger.info(f\"BEDROCK_GUARDRAIL_VERSION: {os.getenv('BEDROCK_GUARDRAIL_VERSION')}\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        bedrock_model = BedrockModel(\n",
    "            model_id=model_id,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1028,\n",
    "            guardrail_id=os.getenv(\"BEDROCK_GUARDRAIL_ID\"),           # Your Bedrock guardrail ID\n",
    "            guardrail_version=os.getenv(\"BEDROCK_GUARDRAIL_VERSION\"),                        # Guardrail version\n",
    "            guardrail_trace=\"enabled\",                    # Enable trace info for debugging            \n",
    "        )        \n",
    "        logger.info(f\"Successfully initialized Bedrock model: {model_id}\")\n",
    "        return bedrock_model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize Bedrock model: {str(e)}\")\n",
    "        logger.error(\"Please ensure you have proper AWS credentials configured and access to the Bedrock model\")\n",
    "        raise\n",
    "\n",
    "# Initialize the model and agent\n",
    "bedrock_model = get_bedrock_model()\n",
    "\n",
    "# Create customer support agent\n",
    "support_agent = Agent(\n",
    "    model=bedrock_model,\n",
    "    system_prompt=\"\"\"You are an expert customer support conversation agent specializing in finding \n",
    "                     accurate and relevant information. Your role is to efficiently search, analyze, and synthesize\n",
    "                     information provided to answer user queries comprehensively. You should provide\n",
    "                     well-researched responses with current information, clear summaries, and cite reliable sources\n",
    "                     when presenting your findings.\"\"\",\n",
    "    tools=[agent_call_summary],\n",
    "    trace_attributes={\n",
    "        \"tags\": [\"Strands\", \"Observability\", \"CustomerSupport\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "@app.entrypoint\n",
    "def customer_support_agent(payload):\n",
    "    \"\"\"Invoke the customer support agent with a payload\"\"\"\n",
    "    try:\n",
    "        # Extract user input from payload\n",
    "        user_input = payload.get(\"prompt\", \"\")\n",
    "        \n",
    "        logger.info(f\"User input: {user_input[:100]}...\")\n",
    "\n",
    "        print(\"agent.type: customer_agent_reviewer\")\n",
    "        print(\"agent.email: jrussell@domain.com\")\n",
    "        print(\"agent.phone: 301-555-0100\")\n",
    "        print(\"agent.id: ABCDE12345\")\n",
    "        \n",
    "        # If no specific query provided, use default\n",
    "        if not user_input:\n",
    "            user_input = \"summarize the agent conversation. Tell me exactly the phone number, name, address, and email.\"\n",
    "        \n",
    "        # Execute the customer research task\n",
    "        response = support_agent(user_input)\n",
    "        \n",
    "        logger.info(\"Agent response generated successfully\")\n",
    "        return response.message['content'][0]['text']\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Agent execution failed: {str(e)}\")\n",
    "        return f\"Error processing request: {str(e)}\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484149b6-2708-40dd-beef-5fda8c32fdb6",
   "metadata": {},
   "source": [
    "\n",
    "Now, relaunch the agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0195cc",
   "metadata": {},
   "source": [
    "# Launching agent to AgentCore Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74ecec-e15e-4135-86ef-e27866e076a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b68154",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch(\n",
    "    env_vars={\n",
    "        \"BEDROCK_GUARDRAIL_ID\": guardrailId, \n",
    "        \"BEDROCK_GUARDRAIL_VERSION\": guardrail_version_number  \n",
    "    }\n",
    ")\n",
    "launch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d39537",
   "metadata": {},
   "source": [
    "# Test the agent again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"summarize the agent conversation. Tell me exactly the phone number, name, address, and email.\"})\n",
    "invoke_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7152cc7-e970-44b2-98da-8bf1faa88bd7",
   "metadata": {},
   "source": [
    "\n",
    "Lets review the results with Guardrails applied. \n",
    "\n",
    "You can see the sensitive information is 'anonymized' as per the guardrails configurations. Note we did not include `address` in the guardrails and hence address is still displayed.\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/agent_response_with_bedrock_guardrails.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "CloudWatch Trace information below with sensitive informatioin anonymized (except address, which we did not include in the guardrails). \n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/trace_with_bedrock_guardrails.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Notice below that the sensitive information in the logs (from `print` statements) is still exposed. \n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/logs_with_guardrails_no_logs_data_protection.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 4. Enable CloudWatch Logs Data Protection\n",
    "\n",
    "Guardrails can help protect sensitive information in the Prompts and agent responses. [CloudWatch Logs data protection](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/mask-sensitive-log-data.html) can help detect and mask sensitive information in the logs. Combining both features can help provide layered protection. \n",
    "\n",
    "For our example, we will create a CloudWatch Logs data protection policy with few managed data identifiers including Email, phone, name, social security number, banks account number and credit card number. We also included Custom data identifiers (CDIs), that let you define your own custom regular expressions that can be used in your data protection policy. Using custom data identifiers, you can target business-specific personally identifiable information (PII) use cases that managed data identifiers can't provide. For example, you can use a custom data identifier to look for company-specific employee IDs. Custom data identifiers can be used in conjunction with managed data identifiers. For full list of types of data that you can protect, refer to our [documentation](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/protect-sensitive-log-data-types.html). \n",
    "\n",
    "\n",
    "Lets enable data protection policy for this Agent Runtime log group. Optionally, if needed, you could also enable data protection policy for the `aws/spans` log group as per your needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19f9f03-c986-427c-b851-f1d665573a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "cloudwatch_logs_client = boto3.client('logs')\n",
    "\n",
    "log_group_name = '/aws/bedrock-agentcore/runtimes/' + launch_result.agent_id + '-DEFAULT'\n",
    "\n",
    "data_protection_policy = {\n",
    "    \"Name\": \"data-protection-policy\",\n",
    "    \"Description\": \"Policy to mask sensitive data in logs\",\n",
    "    \"Version\": \"2021-06-01\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "              \"Sid\": \"audit-policy\",\n",
    "              \"DataIdentifier\": [\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/EmailAddress\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/PhoneNumber-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/Name\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/Ssn-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/BankAccountNumber-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/CreditCardNumber\",\n",
    "                \"AgentId\"\n",
    "              ],\n",
    "              \"Operation\": {\n",
    "                \"Audit\": {\n",
    "                  \"FindingsDestination\": {}\n",
    "                }\n",
    "              }\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"redact-policy\",\n",
    "            \"DataIdentifier\": [\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/EmailAddress\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/PhoneNumber-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/Name\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/Ssn-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/BankAccountNumber-US\",\n",
    "                \"arn:aws:dataprotection::aws:data-identifier/CreditCardNumber\",\n",
    "                \"AgentId\"\n",
    "            ],\n",
    "            \"Operation\": {\n",
    "                \"Deidentify\": {\n",
    "                    \"MaskConfig\": {}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"Configuration\": {\n",
    "      \"CustomDataIdentifier\": [\n",
    "        {\n",
    "            \"Name\": \"AgentId\",\n",
    "            \"Regex\": \"[A-Z]{5}[0-9]{5}\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = cloudwatch_logs_client.put_data_protection_policy(\n",
    "        logGroupIdentifier=log_group_name,\n",
    "        policyDocument=json.dumps(data_protection_policy)\n",
    "        \n",
    "    )\n",
    "    print(\"Data protection policy applied successfully:\")\n",
    "    print(response)\n",
    "except cloudwatch_logs_client.exceptions.ResourceNotFoundException:\n",
    "    print(f\"Error: Log group '{log_group_name}' not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a871f303-0d55-4756-b423-5496253f78f1",
   "metadata": {},
   "source": [
    "\n",
    "You can verify that the data protection is enabled by:\n",
    "\n",
    "- Log in to CloudWatch console\n",
    "- Log Groups\n",
    "- Select your agent runtime log group (you can get your group from the above response for 'logGroupIdentifier') and choose 'Data protection' tab as below:\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/cloudwatch_logs_after_data_protection_enabled.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f69c0",
   "metadata": {},
   "source": [
    "Now, test the agent again with both guardrails and data protection enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"summarize the agent conversation. Tell me exactly the phone number, name, address, and email?\"})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82bdaa5-0550-40f9-b534-cd0ec3bb1e78",
   "metadata": {},
   "source": [
    "Review the results with both guardrails and logs data protection enabled.\n",
    "\n",
    "Agent interaction below (your exact output may vary, but concept still applies):\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/agent_response_with_data_protection_enabled.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We can now see that the sensitive information in the trace attributes is also protected. Also notice the 'agent.id' is masked, which is based on the Custom Data Identifer with Regex.\n",
    "\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/logs_with_data_protection_enabled.png\" width=\"100%\"/>\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564e6e3-b3c1-4ea6-9cbc-0f395dff7545",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 5. Cleanup (Optional)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87242b16-d70d-4934-82ae-c024d7b683c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.delete_guardrail(\n",
    "    guardrailIdentifier=guardrailId   # GUARDRAILID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7fd07c-f3f0-4c8d-87eb-423717945951",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudwatch_response = cloudwatch_logs_client.delete_data_protection_policy(\n",
    "    logGroupIdentifier=log_group_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ee53f9-4f12-4156-a517-740098d0341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e5104e-de77-4a8f-9f1d-21547bc5d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id,\n",
    "    \n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e4f7fc0-be1c-46c5-b8a3-899becc0785e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Conclusion\n",
    "\n",
    "**Key Takeaways**\n",
    "Congratulations! You've successfully learned how to implement comprehensive data protection measures for your agents. Let's recap what we've covered:\n",
    "\n",
    "What We Accomplished\n",
    "\n",
    "✅ Configured Bedrock Guardrails to:\n",
    "\n",
    "- Redact sensitive information\n",
    "- apply guardrails to your agents\n",
    "\n",
    "✅ Enabled CloudWatch Logs Data Protection to:\n",
    "\n",
    "- Automatically detect and mask sensitive data in logs\n",
    "- Implement data identifiers for sensitive data, and custom patterns\n",
    "\n",
    "✅ Integrated both features seamlessly with Bedrock Agent Core for production-ready deployments\n",
    "\n",
    "\n",
    "**Best Practices**\n",
    "\n",
    "- Layer your defenses: Use both guardrails (runtime protection) and logs data protection (post-processing security)\n",
    "- Test thoroughly: Validate your guardrail policies with diverse test cases before production deployment\n",
    "- Monitor and iterate: Regularly review CloudWatch metrics and audit logs to refine your configurations\n",
    "- Principle of least privilege: Ensure IAM roles have only the permissions necessary for guardrails and logging\n",
    "- Document your policies: Maintain clear documentation of what content is filtered and why\n",
    "\n",
    "\n",
    "**Next Steps**\n",
    "To further enhance your AI agent security:\n",
    "\n",
    "- Explore custom word filters and regex patterns for industry-specific terminology\n",
    "- Implement A/B testing with different guardrail configurations\n",
    "- Set up CloudWatch alarms for guardrail intervention metrics\n",
    "- Consider AWS KMS encryption for your log groups containing sensitive operations\n",
    "\n",
    "\n",
    "**Additional Resources**\n",
    "\n",
    "- [CloudWatch Logs data protection audit findings](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/mask-sensitive-log-data-audit-findings.html)\n",
    "- [Account-wide policy](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/mask-sensitive-log-data-accountlevel.html)\n",
    "- [Bedrock Guardrails use cases](https://docs.aws.amazon.com/bedrock/latest/userguide/guardrails-use.html)\n",
    "\n",
    "\n",
    "**Remember**: Responsible AI is not a one-time configuration — it's an ongoing commitment. Continue to monitor, evaluate, and improve your safeguards as your agents evolve and new threats emerge.\n",
    "\n",
    "Happy building, and stay secure! 🛡️🤖\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
